{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basavaraj.nlp project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akcp6E2rawuQ",
        "colab_type": "text"
      },
      "source": [
        "#                                           #Classification probblem on reuters newswire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-YVnqEK1_35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDMhx2Yb8koG",
        "colab_type": "text"
      },
      "source": [
        "Reuters data set is  available in NLTK library.http://www.nltk.org/nltk_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EjtQa4s8sw1",
        "colab_type": "text"
      },
      "source": [
        "It contains structured information about newswire articles that can be assigned to several classes, making it a multi-label problem.The collection originally consisted of 21,578 documents but a subset and split is traditionally used. The most common split is Mod-Apte which only considers categories that have at least one document in the training set and the test set. The Mod-Apte split has 90 categories with a training set of 7769 documents and a test set of 3019 documents.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-S_X8EX95Cr",
        "colab_type": "text"
      },
      "source": [
        "NLTK has built-in support for dozens of corpora and trained models. To use these within NLTK we recommend that you use the NLTK corpus downloader, >>> nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYH_fW_n16Jc",
        "colab_type": "code",
        "outputId": "1ba38d8d-b1c7-493e-a2ce-89663cf461b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('reuters')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ao3XeDV-gLI",
        "colab_type": "text"
      },
      "source": [
        "*`In natural language processing, useless words (data), are referred to as stop words. Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.`*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhAeEail2SoU",
        "colab_type": "code",
        "outputId": "57c826ff-dd71-424f-a99a-a17100ac8b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pqgny_f4BnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import reuters\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig76Ms8X-ONk",
        "colab_type": "text"
      },
      "source": [
        "**Setting up train & Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzmOXNNy4k3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_documents, train_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('training/')])\n",
        "test_documents, test_categories = zip(*[(reuters.raw(i), reuters.categories(i)) for i in reuters.fileids() if i.startswith('test/')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpn9hyAn_lr0",
        "colab_type": "text"
      },
      "source": [
        "Tokenize returns a list of stems that appear in the text that was passed as an argument. Stop-words are filtered out, as well as words that are too short. Furthermore, any string that contains other than letters is removed (e.g., numbers).\n",
        "Here I have used porter stemmer to stem the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LII9G5ttv8Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UBlga-h4Cew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stems = []\n",
        "    for item in tokens:\n",
        "        stems.append(PorterStemmer().stem(item))\n",
        "    return stems"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YNVprhnAaX_",
        "colab_type": "text"
      },
      "source": [
        "The above cell defines a function tokenize that performs following actions:\n",
        "\n",
        "Receive a document as an argument to the function\n",
        "\n",
        "Tokenize the document using nltk.word_tokenize()\n",
        "\n",
        "Use PorterStemmer provided by the nltk to remove morphological affixes from each token\n",
        "\n",
        "Append stemmed token to an already defined list stems\n",
        "\n",
        "Return the list stems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEEqOjCR41TX",
        "colab_type": "code",
        "outputId": "2f7d63f3-dffb-40a5-e885-d0468bfe62b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s5oXzL_GtXv",
        "colab_type": "text"
      },
      "source": [
        "**TF ** =  *Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization*\n",
        "\n",
        "**TF(t)** = *(Number of times term t appears in a document) / (Total number of terms in the document).*\n",
        "\n",
        "**IDF**: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:*\n",
        "\n",
        "**IDF(t)** = log_e(Total number of documents / Number of documents with term t in it).*\n",
        "\n",
        "**Example:**\n",
        "\n",
        "Consider a document containing 100 words wherein the word cat appears 3 times.\n",
        "\n",
        "*The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. Now, assume we have 10 million documents and the word cat appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12.* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxKDQAil_9HD",
        "colab_type": "text"
      },
      "source": [
        "To begin, I first used TF-IDF for feature selection on both train as well as test data using TfidfVectorizer.\n",
        "\n",
        "But first, What TfidfVectorizer actually does?\n",
        "\n",
        "TfidfVectorizer converts a collection of raw documents to a matrix of TF-IDF features.\n",
        "TF-IDF?\n",
        "\n",
        "*TFIDF (abbreviation of the term frequency–inverse document frequency)* is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. tf–idf\n",
        "Why TfidfVectorizer?\n",
        "\n",
        "*TfidfVectorizer *scale down the impact of tokens that occur very frequently (e.g., “a”, “the”, and “of”) in a given corpus. Feature Extraction and Transformation\n",
        "I gave following two arguments to TfidfVectorizer:\n",
        "\n",
        "*tokenizer: tokenize function\n",
        "stop_words *\n",
        "Then I used *fit_transform* and transform on the train and test documents repectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUCf8NXM34qt",
        "colab_type": "code",
        "outputId": "e64f28b6-4c11-4ecb-dec5-07d8d190c788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer = tokenize, stop_words = 'english')\n",
        "\n",
        "vectorised_train_documents = vectorizer.fit_transform(train_documents)\n",
        "vectorised_test_documents = vectorizer.transform(test_documents)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eiRC6Wu4ObU",
        "colab_type": "text"
      },
      "source": [
        "**1.Firstly, the data representation for the category assignment to the different documents is slightly different, viewing each document as a list of bits representing being or not in each of the categories. This change is done by using the MultiLabelBinarizer as the code shows.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8hUualE2fgo",
        "colab_type": "text"
      },
      "source": [
        "The problem we are solving has a multi-label nature, and because of this, there are two changes that I have to made in the code that are not needed for binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGMWw5un4F90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "train_labels = mlb.fit_transform(train_categories)\n",
        "test_labels = mlb.transform(test_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNaSfWSh3zyt",
        "colab_type": "text"
      },
      "source": [
        "**2.Secondly, we have to train our model (which is binary by nature) N times, once per category, where the negative cases will be the documents in all the other categories. This allows our model to make a binary decision per category and produce multi-label results. This can be done with the OneVsRestClassifier object in Scikit-learn.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P-g6HVx7DTv",
        "colab_type": "text"
      },
      "source": [
        "[youtube link for one vs rest classifier explained by Andrew NG](https://www.youtube.com/watch?v=ZvaELFv5IpM)\n",
        "\n",
        "[Another yoytube link to understand one vs rest classifier](https://www.youtube.com/watch?v=6_YvpI-oDIs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cro7gWoF4MBE",
        "colab_type": "code",
        "outputId": "5cbdf113-cb27-476b-ff99-b50d83265422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "classifier = OneVsRestClassifier(LinearSVC())\n",
        "classifier.fit(vectorised_train_documents, train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "     verbose=0),\n",
              "          n_jobs=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTT1Jdp665Z4",
        "colab_type": "text"
      },
      "source": [
        "I used KFold with cross_val_score as KFold supports shuffling the data.\n",
        "\n",
        "I also enabled random_state as 42"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVwhbDqh4NEN",
        "colab_type": "code",
        "outputId": "6a50b2ad-309e-49cb-9dd6-36db198c25e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "kf = KFold(n_splits=10, random_state = 42, shuffle = True)\n",
        "scores = cross_val_score(classifier, vectorised_train_documents, train_labels, cv = kf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 70 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 79 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 14 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 28 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 42 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 51 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:76: UserWarning: Label not 5 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzoxCMPQ4Q32",
        "colab_type": "code",
        "outputId": "f62af18e-d4b2-4829-91e0-d6362e387cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Cross-validation scores:', scores)\n",
        "print('Cross-validation accuracy: {:.4f} (+/- {:.4f})'.format(scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validation scores: [0.83655084 0.86743887 0.8043758  0.83011583 0.83655084 0.81724582\n",
            " 0.82754183 0.8030888  0.80694981 0.82731959]\n",
            "Cross-validation accuracy: 0.8257 (+/- 0.0368)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsLQfe1x4sZM",
        "colab_type": "text"
      },
      "source": [
        "***Evaluation***\n",
        "\n",
        "Measuring the quality of a classifier is a necessary step in order to potentially improve it. The main metrics for Text Classification are:\n",
        "\n",
        "*Precision:* Number of documents correctly assigned to a category out of the total number of documents predicted.\n",
        "\n",
        "*Recall*: Number of documents correctly assigned to a category out of the total number of documents in such category.\n",
        "\n",
        "*F1*: Metric that combines precision and recall using the harmonic mean.\n",
        "If the evaluation is being done in multi-class or multi-label environments, the method becomes slightly more complicated because the quality metrics have to be either shown per category, or globally aggregated. There are two main aggregation approaches:\n",
        "\n",
        "**Micro-average:**  This will aggregate the contribution from all classes to compute the average metric.\n",
        "\n",
        "**Macro-average:** This will compute the metric independently for each class then take the average.\n",
        "\n",
        "[Reference for detailed explanation about micro and macro averages](https://datascience.stackexchange.com/a/24051)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPT1rwDE4Chx",
        "colab_type": "code",
        "outputId": "eb6124e4-0380-4326-9de3-0426d1b6ba7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "predictions = classifier.predict(vectorised_test_documents)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "\n",
        "macro_precision = precision_score(test_labels, predictions, average='macro')\n",
        "macro_recall = recall_score(test_labels, predictions, average='macro')\n",
        "macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
        "\n",
        "micro_precision = precision_score(test_labels, predictions, average='micro')\n",
        "micro_recall = recall_score(test_labels, predictions, average='micro')\n",
        "micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
        "\n",
        "cm = confusion_matrix(test_labels.argmax(axis = 1), predictions.argmax(axis = 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mljvE6s25qPF",
        "colab_type": "code",
        "outputId": "54c4362c-c95a-4c16-feb8-bcc5173a4d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "print(\"Accuracy: {:.4f}\\nPrecision:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\\nRecall:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\\nF1-measure:\\n- Macro: {:.4f}\\n- Micro: {:.4f}\".format(accuracy, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8099\n",
            "Precision:\n",
            "- Macro: 0.6076\n",
            "- Micro: 0.9471\n",
            "Recall:\n",
            "- Macro: 0.3708\n",
            "- Micro: 0.7981\n",
            "F1-measure:\n",
            "- Macro: 0.4410\n",
            "- Micro: 0.8662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoWtf1W1k9vU",
        "colab_type": "text"
      },
      "source": [
        "# **using pickle object to predict the given text or file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk_nN6ROjrJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYOXMi0vjrOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('classifier.pickle','wb') as f:\n",
        "    pickle.dump(classifier,f)\n",
        "    \n",
        "# Saving the Tf-Idf model\n",
        "with open('tfidfmodel.pickle','wb') as f:\n",
        "    pickle.dump(vectorizer,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGcDPqe-jrUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the vectorizer and classfier\n",
        "with open('classifier.pickle','rb') as f:\n",
        "    classifier = pickle.load(f)\n",
        "    \n",
        "with open('tfidfmodel.pickle','rb') as f:\n",
        "    tfidf = pickle.load(f)    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_HFjCPtM2PB",
        "colab_type": "text"
      },
      "source": [
        "**PREDICTING THE GVEN TEXT OR TEXT FILE CATEGORY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHrGzBOejraS",
        "colab_type": "code",
        "outputId": "46881896-7185-4570-cfb5-1eb5074c000d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sent = classifier.predict(tfidf.transform([\"this is a copper can\"]).toarray())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l154ryJ-jrgN",
        "colab_type": "code",
        "outputId": "9602e354-bfc4-4ebd-8246-3a40ea7ffe8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "sent"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuTasbt9lKYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myfile = open('14826.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ1_Z_9clYQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "senet = classifier.predict(tfidf.transform([myfile.read()]).toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjd_HOd0pnat",
        "colab_type": "code",
        "outputId": "5c3aa634-c8e3-497c-9b30-1bf36a1a67bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "senet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUxgPgvXCTAH",
        "colab_type": "code",
        "outputId": "1d8e54cd-f0be-495b-b9a3-fb684d67ddae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "categories = reuters.categories();\n",
        "\n",
        "print(categories)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afTRKy-VCS7X",
        "colab_type": "code",
        "outputId": "b404a07b-9821-4ad2-992e-40b7fb4c02d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "categories[84]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'trade'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10dRkCE6CtoO",
        "colab_type": "code",
        "outputId": "c405be0f-762d-4b5f-a7f8-25a682f04cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "categories[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'copper'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}